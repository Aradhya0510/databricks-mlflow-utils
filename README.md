# MLflow Model Converter for Predictions, Probabilities, SHAP, and Natural Language Explanations

A Python package that simplifies the conversion of existing MLflow models to return predictions, probabilities, SHAP explanations, and natural language explanations. It ensures consistency of model dependencies during repackaging, making it particularly useful in scenarios like Databricks AutoML, where the best run models typically return only predictions by default.

## Table of Contents

- [Features](#features)
- [Why Use This Package](#why-use-this-package)
- [Installation](#installation)
- [Usage](#usage)
  - [Convert a Model to Return Predictions and Probabilities](#convert-a-model-to-return-predictions-and-probabilities)
  - [Convert a Model to Include SHAP Explanations](#convert-a-model-to-include-shap-explanations)
  - [Convert a Model to Include Natural Language Explanations](#convert-a-model-to-include-natural-language-explanations)
- [How It Works](#how-it-works)
  - [ConvertToPyFuncForProbability Class](#converttopyfuncforprobability-class)
  - [ConvertToPyFuncForExplanation Class](#converttopyfuncforexplanation-class)
  - [NaturalLanguageExplainer Class](#naturallanguageexplainer-class)
  - [DependencyChecker Class](#dependencychecker-class)
- [Example Scenario: Databricks AutoML](#example-scenario-databricks-automl)
- [Contributing](#contributing)
- [License](#license)

## Features

- **Convert Existing MLflow Models**: Transform any existing MLflow model to return both predictions and probabilities without retraining.
- **Generate SHAP Explanations**: Add SHAP-based explanations for model predictions using a seamless API.
- **Natural Language Explanations**: Generate human-readable explanations for model predictions using Large Language Models (LLMs).
- **Dependency Consistency**: Automatically checks and aligns the model's dependencies to ensure consistency with the original environment.
- **Simple API**: Provides an easy-to-use interface that requires only a few lines of code.
- **Seamless Integration**: Designed to work smoothly with MLflow models generated by tools like Databricks AutoML.

## Why Use This Package

In real-world applications, it's essential to have access to both the predicted classes and their associated probabilities, along with understanding why certain predictions were made (explainability). However, some automated machine learning tools, such as Databricks AutoML, log the best run models in MLflow to return only predictions by default. Modifying these models to include probabilities and explanations can be complex due to the need to handle:

- Multiple components that need adjustment.
- Ensuring environment consistency during repackaging.
- Managing dependencies and versions to match the original training environment.
- Generating SHAP explanations, which often require custom code.
- Creating human-readable explanations that can be easily understood by non-technical stakeholders.

This package simplifies the entire process, allowing you to convert existing MLflow models to return predictions, probabilities, generate SHAP explanations, and provide natural language explanations effortlessly.

## Installation

You can install the package directly from GitHub:

```bash
pip install git+https://github.com/Aradhya0510/databricks-mlflow-utils.git
```

## Usage

### Convert a Model to Return Predictions and Probabilities

```python
from databricks_mlflow_utils import get_probabilities

# Replace with your actual model URI
model_uri = "runs:/<run_id>/model"

# Create an instance of the converter
converter = get_probabilities.ConvertToPyFuncForProbability(model_uri)

# Perform the conversion
result = converter.convert()

# Output the URI of the converted model
print("Converted model URI:", result["converted_model_uri"])
```

### Convert a Model to Include SHAP Explanations

```python
from databricks_mlflow_utils.explainations import get_explanations

# Assuming you have a model logged in MLflow and you have its model URI
model_uri = "runs:/<run_id>/model"

# Create an instance of the converter
converter = get_explanations.ConvertToPyFuncForExplanation(model_uri)

# Inspect the model pipeline to get the expected columns
from sklearn.pipeline import Pipeline
from databricks.automl_runtime.sklearn.column_selector import ColumnSelector

# Check if the model is a Pipeline
if isinstance(converter.model, Pipeline):
    for name, step in converter.model.named_steps.items():
        if isinstance(step, ColumnSelector):
            expected_columns = step.cols
            print(f"Columns expected by the model: {expected_columns}")
else:
    print("Model is not a scikit-learn Pipeline.")

# Prepare the dataset for the explainer
# Define the catalog, schema, and table names
catalog = "your_catalog"
schema = "your_schema"
table = "your_table"

# Read the table from Unity Catalog
spark_df = spark.read.table(f"{catalog}.{schema}.{table}")

# Convert the Spark DataFrame to a Pandas DataFrame
pandas_df = spark_df.toPandas()

# Ensure the DataFrame has the expected columns
data_for_explainer = pandas_df[expected_columns]

# Ensure the DataFrame is indexed correctly
data_for_explainer = data_for_explainer.reset_index(drop=True)
print(f"Dataset columns: {data_for_explainer.columns.tolist()}")

# Create the explainer with your dataset
converter.create_explainer(data_for_explainer)

# Now you can convert the model
result = converter.convert()

# The result contains the URI of the converted model
converted_model_uri = result["converted_model_uri"]
print(f"Converted model URI: {converted_model_uri}")

import mlflow

# Load the converted model
wrapped_model = mlflow.pyfunc.load_model(converted_model_uri)

# Prepare some input data (make sure it matches the model's expected input)
input_data = data_for_explainer.sample(5)  # Sample 5 rows for testing

# Get predictions and explanations
output = wrapped_model.predict(input_data)

print("Predictions and Explanations:")
print(output)
```

### Convert a Model to Include Natural Language Explanations

```python
from databricks_mlflow_utils.explainations import get_explanations

# Assuming you have a model logged in MLflow and you have its model URI
model_uri = "runs:/<run_id>/model"

# Set up environment variables for LLM parameters
import os
os.environ['LLM_API_KEY'] = 'your_api_key_here'
os.environ['LLM_BASE_URL'] = 'https://your_llm_base_url'
os.environ['LLM_MODEL_NAME'] = 'your_llm_model_name'

# OR provide llm_params dict e.g.
lm_params = {
                'api_key': api_key,
                'base_url': base_url,
                'model': model_name,
                'max_tokens':200,  # Adjusted to accommodate the word limit
                'temperature':0.7,  # Adjusted for creativity balance
                'top_p':1,
            }
# Create an instance of the converter with NLE=True to enable Natural Language Explanations
converter = get_explanations.ConvertToPyFuncForExplanation(model_uri, NLE=True, llm_params=llm_params)

# Prepare the dataset for the explainer (as in the previous example)
# ...

# Create the explainer with your dataset
converter.create_explainer(data_for_explainer)

# Now you can convert the model
result = converter.convert()

# The result contains the URI of the converted model
converted_model_uri = result["converted_model_uri"]
print(f"Converted model URI: {converted_model_uri}")

import mlflow

# Load the converted model
wrapped_model = mlflow.pyfunc.load_model(converted_model_uri)

# Prepare some input data (make sure it matches the model's expected input)
input_data = data_for_explainer.sample(5)  # Sample 5 rows for testing

# Get predictions, SHAP values, and natural language explanations
output = wrapped_model.predict(input_data)

print("Predictions, SHAP Values, and Natural Language Explanations:")
print(output)
```

**Notes:**

- The `model_uri` should point to the MLflow model you wish to convert.
- The converted model will be logged to MLflow and can be accessed using the returned URI.
- Ensure that the environment variables `LLM_API_KEY`, `LLM_BASE_URL`, and `LLM_MODEL_NAME` are set appropriately for your LLM service or provide a complete llm_params dict.
- The package integrates with LLMs that follow the OpenAI API interface.

## How It Works

### ConvertToPyFuncForProbability Class

This class handles the conversion of an existing MLflow model to return both predictions and probabilities:

- **Loads the Original Model**: Retrieves the model from the specified MLflow run.
- **Ensures Dependency Consistency**: Uses the `DependencyChecker` class to verify and install required dependencies, ensuring the model runs in an environment consistent with the original training environment.
- **Generates Signature and Input Example**: Infers the model's input and output signature for accurate predictions.
- **Logs the New Model**: Creates a new MLflow model that wraps the original model and modifies the `predict` method to return both predictions and probabilities.

### ConvertToPyFuncForExplanation Class

This class extends functionality by adding SHAP-based explanations and natural language explanations to the model:

- **Loads the Original Model and Explainer**: Retrieves the model and explainer from MLflow artifacts.
- **Creates SHAP Explainer**: Automatically selects the appropriate SHAP explainer based on the model type and flavor.
- **Generates Signature and Input Example**: Infers the model's input and output signature, including SHAP values.
- **Natural Language Explanations**: When `NLE=True` is passed, integrates with LLMs to generate human-readable explanations based on SHAP values.
- **Logs the New Model**: Logs a new model in MLflow that returns predictions, probabilities, SHAP explanations, and natural language explanations when queried.

### NaturalLanguageExplainer Class

This class is responsible for generating natural language explanations using SHAP values and an LLM:

- **Integrates with LLMs**: Connects to an LLM service (following the OpenAI API interface) to generate explanations.
- **Generates Individual Explanations**: Produces natural language explanations for individual predictions.
- **Generates Global Explanations**: Provides overall model explanations based on feature importance.
- **Customizable**: Allows passing LLM parameters such as API keys, base URLs, and model names.

### DependencyChecker Class

This class ensures that the dependencies required by the model are consistent with those in the original training environment:

- **Retrieves Required Packages**: Extracts the list of dependencies from the original MLflow model.
- **Checks Python Version**: Verifies that the Python version matches the one used during training.
- **Installs Missing Packages**: Automatically installs any missing packages or versions to match the original environment.

## Example Scenario: Databricks AutoML

When using Databricks AutoML, the best run models are logged in MLflow but return only predictions by default. In many cases, especially in classification tasks, you need both the predicted classes and the probabilities for each class, as well as explanations to make informed decisions.

Manually modifying the logged model to include probabilities and explanations involves several complex steps:

- **Creating a PyFunc Wrapper**: You need to write a custom Python function (pyfunc) wrapper that modifies the predict method to return predictions, probabilities, SHAP explanations, and natural language explanations.
- **Re-logging the Model with Updated Artifacts**: After wrapping, you must re-log the model to MLflow, ensuring that all artifacts are correctly updated.
- **Ensuring Dependency Consistency**: The environment in which the model was trained may have specific versions of libraries. You need to replicate this environment to avoid compatibility issues.
- **Handling Version Conflicts**: Different versions of libraries (e.g., scikit-learn, pandas) can lead to runtime errors if not properly managed.
- **Advanced MLflow Manipulations**: Modifying and repackaging MLflow models requires a deep understanding of MLflow's APIs and best practices.
- **Integrating with LLMs**: Connecting to LLM services and generating explanations adds an additional layer of complexity.
- **Potential Slowdowns in Productionization**: For users unfamiliar with these advanced concepts, the process can be time-consuming and may delay the deployment of models to production.

This package automates the entire process:

- **Simplifies Repackaging**: With just a few lines of code, you can convert the model to return predictions, probabilities, SHAP explanations, and natural language explanations.
- **Maintains Environment Consistency**: The `DependencyChecker` ensures that the model's dependencies are consistent with the original environment, avoiding runtime errors.
- **Integrates Seamlessly**: Works out of the box with models generated by Databricks AutoML and other MLflow-compatible tools.
- **LLM Integration**: Easily connect to your LLM service to generate human-readable explanations without extensive setup.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request on GitHub.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.